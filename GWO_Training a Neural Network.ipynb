{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8072d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9aff022a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregando dados \n",
    "\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "np.size(y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "105c9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento e teste\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a63b63a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arquitetura da rede\n",
    "n_inputs = 13 # features\n",
    "n_hidden = 20 \n",
    "n_classes = 3\n",
    "num_samples = X_train.shape[0] \n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "72884479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_function(p,X_train):\n",
    "    \"\"\" Calculate roll-back the weights and biases\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    p: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of logits for layer 2\n",
    "\n",
    "    \"\"\"\n",
    "    #coeficientes\n",
    "    c1 = n_hidden*n_inputs\n",
    "    c2 = c1 +n_hidden\n",
    "    c3 = c2 + (n_hidden*n_hidden)\n",
    "    c4=  c3 + n_hidden\n",
    "    c5 = c4+(n_hidden*n_classes)\n",
    "    \n",
    "     # First layer weights\n",
    "    W1 = p[0:c1].reshape(n_inputs, n_hidden) - 1\n",
    "    \n",
    "    # First layer bias\n",
    "    b1 = p[c1:c2].reshape(( n_hidden,))\n",
    "    \n",
    "    # Second layer weights\n",
    "    W2 = p[c2:c3].reshape(n_hidden, n_hidden) - 1\n",
    "    \n",
    "    # Second layer bias\n",
    "    b2 = p[c3:c4].reshape(( n_hidden,))\n",
    "    W3 = p[c4:c5].reshape(n_hidden, n_classes) - 1\n",
    "    b3 = p[c5:c5+n_classes].reshape((n_classes,))\n",
    "    \n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X_train.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    #Third linear step\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    \n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    logits = z3\n",
    "   \n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "    return logits          # Logits for Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "673821d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_prop(params):\n",
    "    \"\"\"Forward propagation as objective function\n",
    "\n",
    "    This computes for the forward propagation of the neural network, as\n",
    "    well as the loss.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    params: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed negative log-likelihood loss given the parameters\n",
    "    \"\"\"\n",
    "\n",
    "    logits = logits_function(params,X_train)\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y_train])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "    #print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de406a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"Higher-level method to do forward_prop in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    \n",
    "    n_particles = x.shape[0]\n",
    "    j = forward_prop(x)\n",
    "    #print(x)\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a64e7773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25209508, 0.06612486, 0.90369848, ..., 0.27777486, 0.46515225,\n",
       "        0.43433936],\n",
       "       [0.8974262 , 0.18404395, 0.95553209, ..., 0.09360644, 0.02440444,\n",
       "        0.34714965],\n",
       "       [0.11689259, 0.10042677, 0.41980217, ..., 0.71659302, 0.26221665,\n",
       "        0.09152992],\n",
       "       ...,\n",
       "       [0.18316936, 0.53781628, 0.49219322, ..., 0.01584445, 0.05972254,\n",
       "        0.9465807 ],\n",
       "       [0.11606714, 0.26096807, 0.89160808, ..., 0.0029388 , 0.76783484,\n",
       "        0.12396341],\n",
       "       [0.73386281, 0.35831051, 0.87574029, ..., 0.93833616, 0.59341244,\n",
       "        0.50599432]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Inicialização das soluções\n",
    "xlsfile = pd.ExcelFile('solucao_inicial.xlsx')\n",
    "sol = xlsfile.parse('Sheet1')\n",
    "sol = sol[sol.columns[1:]]\n",
    "initpos = sol.to_numpy()\n",
    "initpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "27df681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWO:\n",
    "     def __init__(self,n_agents,max_iters,dim,lb,up):\n",
    "         \n",
    "        self.lb = lb\n",
    "        self.ub = up\n",
    "        self.max_ite = max_iters\n",
    "        self.dim = dim\n",
    "        self.SearchAgents_no = n_agents\n",
    "        self.Positions = np.zeros((n_agents, dim)) #lista referente a populacao corrente\n",
    "        self.hist = []#lista referente ao historico\n",
    "        # initialize alpha, beta, and delta_pos\n",
    "        self.Alpha_pos = np.zeros(dim)\n",
    "        self.Alpha_score = float(\"inf\")\n",
    "        \n",
    "        self.Beta_pos = np.zeros(dim)\n",
    "        self.Beta_score = float(\"inf\")\n",
    "\n",
    "        self.Delta_pos = np.zeros(dim)\n",
    "        self.Delta_score = float(\"inf\")\n",
    "        \n",
    "     def gerar_populacao(self):\n",
    "        self.Positions = initpos\n",
    "        return\n",
    "    \n",
    "     def calculateFitness(self):\n",
    "        for i in range(0, self.SearchAgents_no):\n",
    "            for j in range(self.dim):\n",
    "                self.Positions[i, j] = np.clip(self.Positions[i, j], self.lb[j], self.ub[j])\n",
    "            \n",
    "            fitness = f(self.Positions[i,:])\n",
    "            if fitness < self.Alpha_score:\n",
    "                self.Delta_score = self.Beta_score  # Update delte\n",
    "                self.Delta_pos = self.Beta_pos.copy()\n",
    "                self.Beta_score = self.Alpha_score  # Update beta\n",
    "                self.Beta_pos = self.Alpha_pos.copy()\n",
    "                self.Alpha_score = fitness\n",
    "                # Update alpha\n",
    "                self.Alpha_pos = self.Positions[i, :].copy()\n",
    "\n",
    "            if fitness > self.Alpha_score and fitness < self.Beta_score:\n",
    "                self.Delta_score = self.Beta_score  # Update delte\n",
    "                self.Delta_pos = self.Beta_pos.copy()\n",
    "                self.Beta_score = fitness  # Update beta\n",
    "                self.Beta_pos = self.Positions[i, :].copy()\n",
    "\n",
    "            if fitness > self.Alpha_score and fitness > self.Beta_score and fitness < self.Delta_score:\n",
    "                self.Delta_score = fitness  # Update delta\n",
    "                self.Delta_pos = self.Positions[i, :].copy()\n",
    "        return\n",
    "    \n",
    "     def updateWolves(self,a):\n",
    "        for i in range(0, self.SearchAgents_no):\n",
    "            for j in range(0, self.dim):\n",
    "                r1 = random.random()  # r1 is a random number in [0,1]\n",
    "                r2 = random.random()  # r2 is a random number in [0,1]\n",
    "\n",
    "                A1 = 2 * a * r1 - a\n",
    "                # Equation (3.3)\n",
    "                C1 = 2 * r2\n",
    "                # Equation (3.4)\n",
    "\n",
    "                D_alpha = abs(C1 * self.Alpha_pos[j] - self.Positions[i, j])\n",
    "                # Equation (3.5)-part 1\n",
    "                X1 = self.Alpha_pos[j] - A1 * D_alpha\n",
    "                # Equation (3.6)-part 1\n",
    "\n",
    "                r1 = random.random()\n",
    "                r2 = random.random()\n",
    "\n",
    "                A2 = 2 * a * r1 - a\n",
    "                # Equation (3.3)\n",
    "                C2 = 2 * r2\n",
    "                # Equation (3.4)\n",
    "\n",
    "                D_beta = abs(C2 * self.Beta_pos[j] - self.Positions[i, j])\n",
    "                # Equation (3.5)-part 2\n",
    "                X2 = self.Beta_pos[j] - A2 * D_beta\n",
    "                # Equation (3.6)-part 2\n",
    "\n",
    "                r1 = random.random()\n",
    "                r2 = random.random()\n",
    "\n",
    "                A3 = 2 * a * r1 - a\n",
    "                # Equation (3.3)\n",
    "                C3 = 2 * r2\n",
    "                # Equation (3.4)\n",
    "\n",
    "                D_delta = abs(C3 * self.Delta_pos[j] - self.Positions[i, j])\n",
    "                # Equation (3.5)-part 3\n",
    "                X3 = self.Delta_pos[j] - A3 * D_delta\n",
    "                # Equation (3.5)-part 3\n",
    "\n",
    "                self.Positions[i, j] = (X1 + X2 + X3) / 3  # Equation (3.7)\n",
    "        return\n",
    "    \n",
    "     def Evaluate(self):\n",
    "        self.gerar_populacao()\n",
    "        for l in range(0, self.max_ite):\n",
    "            self.calculateFitness()\n",
    "            a =  2 - l * ((2) / self.max_ite)\n",
    "            self.updateWolves(a)\n",
    "            self.hist.append(self.Alpha_score)\n",
    "        return\n",
    "    \n",
    "  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd474b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call instance of GWO\n",
    "dimensions = (n_inputs * n_hidden) + (n_hidden * n_hidden)+(n_hidden*n_classes) + 2*n_hidden + n_classes\n",
    "max_ite = 1000\n",
    "n_agents = 100\n",
    "lb = [-2]*dimensions\n",
    "up = [2]*dimensions\n",
    "\n",
    "gwo = GWO(n_agents,max_ite,dimensions,lb,up)\n",
    "\n",
    "gwo.Evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a879d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pos):\n",
    "    \"\"\"\n",
    "    Use the trained weights to perform class predictions.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    pos: numpy.ndarray\n",
    "        Position matrix found by the swarm. Will be rolled\n",
    "        into weights and biases.\n",
    "    \"\"\"\n",
    "    logits = logits_function(pos,X_test)\n",
    "    \n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "   \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predict(gwo.Alpha_pos) == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec273987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14943d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
